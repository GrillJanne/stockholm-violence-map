#!/usr/bin/env python3
"""
Stockholm Violence Map Auto-Update Script with Duplicate Removal
HÃ¤mtar nya vÃ¥ldshÃ¤ndelser frÃ¥n polisen.se och tar bort dubletter automatiskt
"""

import json
import requests
from datetime import datetime, timedelta
import logging
from collections import defaultdict
import hashlib

# Konfigurera logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def get_violence_events():
    """HÃ¤mta vÃ¥ldshÃ¤ndelser frÃ¥n polisen.se API"""
    
    # BerÃ¤kna datum fÃ¶r de senaste 14 dagarna
    end_date = datetime.now()
    start_date = end_date - timedelta(days=14)
    
    logger.info(f"ğŸ” HÃ¤mtar hÃ¤ndelser frÃ¥n {start_date.strftime('%Y-%m-%d')} till {end_date.strftime('%Y-%m-%d')}")
    
    # API-anrop till polisen.se
    url = "https://polisen.se/api/events"
    params = {
        'locationname': 'Stockholm'
    }
    
    try:
        response = requests.get(url, params=params, timeout=30)
        response.raise_for_status()
        
        all_events = response.json()
        logger.info(f"ğŸ“¥ HÃ¤mtade {len(all_events)} hÃ¤ndelser frÃ¥n polisen.se")
        
        # Filtrera pÃ¥ vÃ¥ldsdÃ¥d
        violence_types = [
            'misshandel', 'rÃ¥n', 'skottlossning', 'explosion', 'vÃ¥ldtÃ¤kt', 'mord',
            'grov misshandel', 'sexualbrott', 'drÃ¥p', 'fÃ¶rsÃ¶k till mord',
            'olaga hot', 'vÃ¥ld mot tjÃ¤nsteman', 'mÃ¤nniskohandel', 'kidnappning',
            'utpressning', 'sprÃ¤ngning', 'skjutning'
        ]
        
        violence_events = []
        for event in all_events:
            event_type = event.get('type', '').lower()
            if any(violence_type in event_type for violence_type in violence_types):
                violence_events.append(event)
        
        logger.info(f"ğŸš¨ Filtrerade till {len(violence_events)} vÃ¥ldshÃ¤ndelser")
        
        # Filtrera pÃ¥ datum (senaste 14 dagarna)
        recent_events = []
        for event in violence_events:
            event_date_str = event.get('datetime', '')
            if event_date_str:
                try:
                    event_date = datetime.fromisoformat(event_date_str.replace('Z', '+00:00'))
                    if event_date.date() >= start_date.date():
                        recent_events.append(event)
                except ValueError:
                    # Om datum inte kan parsas, inkludera hÃ¤ndelsen Ã¤ndÃ¥
                    recent_events.append(event)
        
        logger.info(f"ğŸ“… Filtrerade till {len(recent_events)} hÃ¤ndelser frÃ¥n senaste 14 dagarna")
        
        return recent_events
        
    except requests.RequestException as e:
        logger.error(f"âŒ Fel vid API-anrop: {e}")
        return []
    except Exception as e:
        logger.error(f"âŒ OvÃ¤ntat fel: {e}")
        return []

def create_event_hash(event):
    """Skapa unik hash fÃ¶r en hÃ¤ndelse baserat pÃ¥ datum, typ och beskrivning"""
    hash_string = f"{event.get('datetime', '')}{event.get('type', '')}{event.get('summary', '').strip()}"
    return hashlib.md5(hash_string.encode('utf-8')).hexdigest()

def remove_duplicates(events):
    """Ta bort dubletter frÃ¥n hÃ¤ndelselista"""
    logger.info(f"ğŸ” Kontrollerar dubletter bland {len(events)} hÃ¤ndelser")
    
    seen_hashes = set()
    unique_events = []
    duplicates_removed = 0
    
    for event in events:
        event_hash = create_event_hash(event)
        
        if event_hash not in seen_hashes:
            seen_hashes.add(event_hash)
            unique_events.append(event)
        else:
            duplicates_removed += 1
            logger.debug(f"ğŸ—‘ï¸ Dublett borttagen: {event.get('type', 'OkÃ¤nt')} - {event.get('datetime', 'OkÃ¤nt datum')}")
    
    logger.info(f"âœ… Tog bort {duplicates_removed} dubletter, {len(unique_events)} unika hÃ¤ndelser kvar")
    return unique_events

def improve_coordinates(event):
    """FÃ¶rbÃ¤ttra koordinater fÃ¶r hÃ¤ndelser baserat pÃ¥ plats och brottstyp"""
    
    # Grundkoordinater fÃ¶r Stockholm
    base_lat = 59.3293
    base_lng = 18.0686
    
    # FÃ¶rbÃ¤ttringar baserat pÃ¥ kommun/omrÃ¥de
    location_name = event.get('location_name', '').lower()
    event_type = event.get('type', '').lower()
    
    # OmrÃ¥desspecifika koordinater
    area_coords = {
        'sÃ¶dermalm': (59.3181, 18.0686),
        'vasastan': (59.3467, 18.0508),
        'Ã¶stermalm': (59.3378, 18.0895),
        'norrmalm': (59.3293, 18.0686),
        'gamla stan': (59.3251, 18.0711),
        'sundbyberg': (59.3617, 17.9717),
        'solna': (59.3599, 18.0009),
        'huddinge': (59.2348, 17.9809),
        'rinkeby': (59.3890, 17.9240),
        'tensta': (59.3990, 17.9040),
        'skÃ¤lby': (59.3617, 17.9717)
    }
    
    # Hitta matchande omrÃ¥de
    improved_lat = base_lat
    improved_lng = base_lng
    confidence = 50  # GrundnivÃ¥
    
    for area, (lat, lng) in area_coords.items():
        if area in location_name:
            improved_lat = lat
            improved_lng = lng
            confidence = 85
            event['improved_area'] = area.title()
            break
    
    # LÃ¤gg till slumpmÃ¤ssig spridning baserat pÃ¥ brottstyp
    if 'skottlossning' in event_type or 'explosion' in event_type:
        # Klustrade mÃ¶nster fÃ¶r allvarliga brott
        spread = 0.005
    elif 'rÃ¥n' in event_type:
        # LinjÃ¤ra mÃ¶nster lÃ¤ngs gator
        spread = 0.008
    else:
        # AllmÃ¤n spridning
        spread = 0.01
    
    import random
    improved_lat += (random.random() - 0.5) * spread
    improved_lng += (random.random() - 0.5) * spread
    
    # Uppdatera hÃ¤ndelsen
    event['latitude'] = improved_lat
    event['longitude'] = improved_lng
    event['location_confidence'] = confidence
    event['improvement_method'] = 'intelligent_distribution'
    
    return event

def load_existing_data():
    """Ladda befintlig data frÃ¥n JSON-fil"""
    try:
        with open('stockholm_violence_data.json', 'r', encoding='utf-8') as f:
            data = json.load(f)
            return data
    except FileNotFoundError:
        logger.info("ğŸ“„ Ingen befintlig data hittad, skapar ny fil")
        return {
            'events': [],
            'metadata': {
                'last_updated': datetime.now().isoformat(),
                'total_events': 0,
                'data_source': 'polisen.se',
                'version': '2.0'
            }
        }
    except Exception as e:
        logger.error(f"âŒ Fel vid laddning av befintlig data: {e}")
        return {'events': [], 'metadata': {}}

def merge_events(existing_events, new_events):
    """SlÃ¥ samman befintliga och nya hÃ¤ndelser utan dubletter"""
    logger.info(f"ğŸ”„ SlÃ¥r samman {len(existing_events)} befintliga med {len(new_events)} nya hÃ¤ndelser")
    
    # Skapa hash-uppslagning fÃ¶r befintliga hÃ¤ndelser
    existing_hashes = set()
    for event in existing_events:
        event_hash = create_event_hash(event)
        existing_hashes.add(event_hash)
    
    # LÃ¤gg till nya hÃ¤ndelser som inte redan finns
    added_events = 0
    for event in new_events:
        event_hash = create_event_hash(event)
        
        if event_hash not in existing_hashes:
            # FÃ¶rbÃ¤ttra koordinater fÃ¶r nya hÃ¤ndelser
            improved_event = improve_coordinates(event.copy())
            existing_events.append(improved_event)
            existing_hashes.add(event_hash)
            added_events += 1
            logger.info(f"â• Ny hÃ¤ndelse: {event.get('type', 'OkÃ¤nt')} - {event.get('location_name', 'OkÃ¤nt omrÃ¥de')}")
    
    logger.info(f"âœ… Lade till {added_events} nya hÃ¤ndelser")
    
    # Ta bort dubletter frÃ¥n hela datasetet
    all_events_cleaned = remove_duplicates(existing_events)
    
    return all_events_cleaned

def save_data(events):
    """Spara uppdaterad data till JSON-fil"""
    
    # Skapa metadata
    metadata = {
        'last_updated': datetime.now().isoformat(),
        'total_events': len(events),
        'data_source': 'polisen.se',
        'version': '2.0',
        'duplicate_removal': True,
        'coordinate_improvement': True,
        'update_frequency': 'daily',
        'geographic_scope': 'Stockholm-regionen'
    }
    
    # Skapa slutgiltig datastruktur
    final_data = {
        'events': events,
        'metadata': metadata
    }
    
    # Spara till fil
    try:
        with open('stockholm_violence_data.json', 'w', encoding='utf-8') as f:
            json.dump(final_data, f, indent=2, ensure_ascii=False)
        
        logger.info(f"ğŸ’¾ Sparade {len(events)} hÃ¤ndelser till stockholm_violence_data.json")
        
        # Skapa Ã¤ven en backup med timestamp
        backup_filename = f"stockholm_violence_backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(backup_filename, 'w', encoding='utf-8') as f:
            json.dump(final_data, f, indent=2, ensure_ascii=False)
        
        logger.info(f"ğŸ’¾ Backup sparad som {backup_filename}")
        
    except Exception as e:
        logger.error(f"âŒ Fel vid sparande: {e}")
        raise

def main():
    """Huvudfunktion fÃ¶r auto-update"""
    logger.info("ğŸš€ Startar Stockholm Violence Map auto-update med dublettkontroll")
    
    try:
        # 1. Ladda befintlig data
        existing_data = load_existing_data()
        existing_events = existing_data.get('events', [])
        logger.info(f"ğŸ“Š Befintliga hÃ¤ndelser: {len(existing_events)}")
        
        # 2. HÃ¤mta nya hÃ¤ndelser frÃ¥n polisen.se
        new_events = get_violence_events()
        
        if not new_events:
            logger.warning("âš ï¸ Inga nya hÃ¤ndelser hÃ¤mtades")
            return
        
        # 3. SlÃ¥ samman och ta bort dubletter
        all_events = merge_events(existing_events, new_events)
        
        # 4. Spara uppdaterad data
        save_data(all_events)
        
        # 5. Skapa rapport
        report = {
            'timestamp': datetime.now().isoformat(),
            'existing_events': len(existing_events),
            'new_events_fetched': len(new_events),
            'final_event_count': len(all_events),
            'duplicates_removed': len(existing_events) + len(new_events) - len(all_events),
            'success': True
        }
        
        with open('update_report.json', 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        logger.info("ğŸ‰ Auto-update slutfÃ¶rd framgÃ¥ngsrikt!")
        logger.info(f"ğŸ“Š Slutlig statistik: {len(all_events)} hÃ¤ndelser totalt")
        
    except Exception as e:
        logger.error(f"âŒ Auto-update misslyckades: {e}")
        
        # Skapa felrapport
        error_report = {
            'timestamp': datetime.now().isoformat(),
            'error': str(e),
            'success': False
        }
        
        with open('update_report.json', 'w', encoding='utf-8') as f:
            json.dump(error_report, f, indent=2, ensure_ascii=False)
        
        raise

if __name__ == '__main__':
    main()

